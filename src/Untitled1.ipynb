{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fad7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from head.metrics import CosFace\n",
    "from loss.focal import FocalLoss\n",
    "from utils.utils import separate_resnet_bn_paras, warm_up_lr, load_checkpoint, \\\n",
    "    schedule_lr, AverageMeter, accuracy\n",
    "from utils.fairness_utils import evaluate\n",
    "from utils.data_utils_balanced import prepare_data\n",
    "from utils.utils_train import Network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import timm\n",
    "from utils.utils import save_output_from_dict\n",
    "from utils.utils_train import Network, get_head\n",
    "from utils.fairness_utils import evaluate, add_column_to_file\n",
    "from timm.optim import create_optimizer_v2, optimizer_kwargs\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.utils.model_ema import ModelEmaV2\n",
    "from utils.fairness_utils import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device_ids=range(torch.cuda.device_count())\n",
    "torch.manual_seed(222)\n",
    "torch.cuda.manual_seed_all(222)\n",
    "np.random.seed(222)\n",
    "random.seed(222)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "default_test_root = '/cmlscratch/sdooley1/data/CelebA/Img/img_align_celeba_splits/test/'\n",
    "default_train_root = '/cmlscratch/sdooley1/data/CelebA/Img/img_align_celeba_splits/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97058fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P identities: {'male': 1.0, 'female': 1.0}\n",
      "P images: {'male': 1.0, 'female': 1.0}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--default_test_root', default=default_test_root)\n",
    "parser.add_argument('--default_train_root', default=default_train_root)\n",
    "parser.add_argument('--demographics_file', default= '/cmlscratch/sdooley1/data/CelebA/CelebA_demographics.txt')\n",
    "parser.add_argument('--backbone_name', default='mobilenetv3_large_100')\n",
    "parser.add_argument('--backbone', default='mobilenetv3_large_100')\n",
    "parser.add_argument('--pretrained', default=False)\n",
    "parser.add_argument('--project_name', default=\"from-scratch_no-resampling_adam\")\n",
    "parser.add_argument('--head', default=\"CosFace\")\n",
    "parser.add_argument('--opt', default=\"AdamW\")\n",
    "parser.add_argument('--epochs', default=100)\n",
    "parser.add_argument('--sched', default='cosine')\n",
    "parser.add_argument('--min_lr', default=0.01)\n",
    "\n",
    "parser.add_argument('--checkpoints_root', default='/cmlscratch/sdooley1/merge_timm/FR-NAS/Checkpoints/Phase1B/')\n",
    "parser.add_argument('--head_name', default='CosFace')\n",
    "parser.add_argument('--train_loss', default='Focal', type=str)\n",
    "\n",
    "parser.add_argument('--groups_to_modify', default= ['male', 'female'], type=str, nargs='+')\n",
    "parser.add_argument('--p_identities', default=[1.0, 1.0], type=float, nargs='+')\n",
    "parser.add_argument('--p_images', default=[1.0, 1.0], type=float, nargs='+')\n",
    "parser.add_argument('--min_num_images', default=3, type=int)\n",
    "\n",
    "parser.add_argument('--batch_size', default=250, type=int)\n",
    "parser.add_argument('--input_size', default=112, type=int)\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float)\n",
    "parser.add_argument('--momentum', default=0.9, type=float)\n",
    "parser.add_argument('--mean', default=[0.5, 0.5, 0.5], type=int)\n",
    "parser.add_argument('--std', default=[0.5, 0.5, 0.5], type=int)\n",
    "parser.add_argument('--stages', default=[35, 65, 95], type=int)\n",
    "parser.add_argument('--num_workers', default=4, type=int)\n",
    "\n",
    "parser.add_argument('--lr', default=0.001, type=float)\n",
    "parser.add_argument('--num_epoch', default=3, type=int)\n",
    "parser.add_argument('--gpu_id', default=[0], type=int, nargs='+', help='gpu id')\n",
    "parser.add_argument('--name', default='CelebA', type=str)\n",
    "parser.add_argument('--dataset', default='CelebA', type=str)\n",
    "parser.add_argument('--file_name', default='timm_from-scratch.csv', type=str)\n",
    "parser.add_argument('--seed', default=222, type=int)\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "p_images = {args.groups_to_modify[i]:args.p_images[i] for i in range(len(args.groups_to_modify))}\n",
    "p_identities = {args.groups_to_modify[i]:args.p_identities[i] for i in range(len(args.groups_to_modify))}\n",
    "args.p_images = p_images\n",
    "args.p_identities = p_identities\n",
    "\n",
    "print(\"P identities: {}\".format(args.p_identities))\n",
    "print(\"P images: {}\".format(args.p_images))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd74892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING TRAIN DATASET\n",
      "Overall # of images for male available is 67562\n",
      "# images selected for male is 67562\n",
      "Overall # of images for female available is 76524\n",
      "# images selected for female is 67562\n",
      "Number of idx for male is 3529\n",
      "Number of idx for female is 3529\n",
      "PREPARING TEST DATASET\n",
      "Overall # of images for male available is 7644\n",
      "# images selected for male is 7636\n",
      "Overall # of images for female available is 8851\n",
      "# images selected for female is 7636\n",
      "Number of idx for male is 406\n",
      "Number of idx for female is 406\n",
      "Len of train dataloader is 540\n",
      "Len of test dataloader is 62\n"
     ]
    }
   ],
   "source": [
    "dataloaders, num_class, demographic_to_labels_train, demographic_to_labels_test = prepare_data(args)\n",
    "args.num_class = num_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6970a38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_\n",
      "Found checkpoints for this model: ['Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_80.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_20.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_101.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_60.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_40.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_100.pth']\n",
      "Loading Checkpoint '/cmlscratch/sdooley1/merge_timm/FR-NAS/Checkpoints/Phase1B/mobilenetv3_large_100_CosFace_AdamW/Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_101.pth'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' Model '''\n",
    "backbone = timm.create_model(args.backbone_name, \n",
    "                             num_classes=0,\n",
    "                             pretrained=args.pretrained).to(device)\n",
    "config = timm.data.resolve_data_config({}, model=backbone)\n",
    "model_input_size = config['input_size']\n",
    "\n",
    "# get model's embedding size\n",
    "meta = pd.read_csv('/cmlscratch/sdooley1/timm_model_metadata.csv')\n",
    "embedding_size = int(\n",
    "    meta[meta.model_name == args.backbone].feature_dim)\n",
    "args.embedding_size= embedding_size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "head = get_head(args)\n",
    "train_criterion = FocalLoss(elementwise=True)\n",
    "head,backbone= head.to(device), backbone.to(device)\n",
    "backbone = nn.DataParallel(backbone)\n",
    "####################################################################################################################\n",
    "# ======= argsimizer =======#\n",
    "model = Network(backbone, head)\n",
    "\n",
    "optimizer = create_optimizer_v2(model, **optimizer_kwargs(cfg=args))\n",
    "\n",
    "model_ema = None\n",
    "model, model_ema, optimizer, epoch, batch, checkpoints_model_root = load_checkpoint(\n",
    "    args, model, model_ema, optimizer, dataloaders[\"train\"], p_identities,\n",
    "    p_images)\n",
    "#model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562d6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:11<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "demographic_to_labels = demographic_to_labels_train\n",
    "loss = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "acc = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "count = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "acc_k = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "intra = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "inter = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "angles_intra, angles_inter, correct = 0, 0, 0\n",
    "\n",
    "#backbone.eval()\n",
    "#if multilabel_accuracy:\n",
    "#    head.eval()\n",
    "model.eval()\n",
    "# figure out embedding size\n",
    "emb_size = embedding_size\n",
    "dataloader = dataloaders['test']\n",
    "if emb_size is None:\n",
    "    inputs, _, _ = next(iter(dataloader))\n",
    "    x = torch.randn(inputs.shape).to(device)\n",
    "    emb_size = backbone(x).shape[1]\n",
    "\n",
    "\n",
    "feature_matrix = torch.empty(0, emb_size)\n",
    "labels_all = []\n",
    "indices_all = []\n",
    "demographic_all = []\n",
    "predicted_all = []\n",
    "\n",
    "for inputs, labels, sens_attr, indices in tqdm(iter(dataloader)):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).long()\n",
    "    labels_all = labels_all + labels.cpu().tolist()\n",
    "    indices_all = indices_all + indices.cpu().tolist()\n",
    "    sens_attr = np.array(sens_attr)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if True:\n",
    "            #need to build feature matrix\n",
    "            inputs_flipped = torch.flip(inputs, [3])\n",
    "            try:\n",
    "                embed = model.module.backbone(inputs) + model.module.backbone(inputs_flipped)\n",
    "            except AttributeError:\n",
    "                embed = model.backbone(inputs) + model.backbone(inputs_flipped)\n",
    "            features_batch = l2_norm(embed)\n",
    "            feature_matrix = torch.cat((feature_matrix, features_batch.detach().cpu()), dim = 0)\n",
    "\n",
    "            demographic_all = demographic_all + sens_attr.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9160439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, labels, demographic_to_labels, test_features, test_labels, test_demographic = feature_matrix, torch.tensor(labels_all), demographic_to_labels, feature_matrix, torch.tensor(labels_all), np.array(demographic_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc1489a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix =  l2_dist(feature_matrix, feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f8a094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2038564682006836\n"
     ]
    }
   ],
   "source": [
    "acc_k = {k:0 for k in demographic_to_labels.keys()}\n",
    "nearest_neighbors = torch.topk(dist_matrix, dim=1, k = 2, largest = False)[1][:,1]\n",
    "n_images = dist_matrix.shape[0]\n",
    "correct = torch.zeros(test_labels.shape)\n",
    "nearest_id = torch.zeros(test_labels.shape)\n",
    "\n",
    "t = time.time()\n",
    "for img in range(n_images):\n",
    "    nearest_label = labels[nearest_neighbors[img]].item()\n",
    "    nearest_id[img] = nearest_label\n",
    "    label_img = test_labels[img].item()\n",
    "    if label_img == nearest_label:\n",
    "        correct[img] = 1\n",
    "print(time.time()-t)\n",
    "for k in acc_k.keys():\n",
    "    acc_k[k] = (correct[test_demographic == k]).mean()\n",
    "\n",
    "# acc_k, \n",
    "# correct = torch.tensor(just_one + 1)\n",
    "# nearest_id = torch.tensor(df[1].apply(lambda x: labels_np[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62e9b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 53.,  53.,  53.,  ..., 576., 662., 406.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07845af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "936ee3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    base_label = labels_np[row[0]]\n",
    "    i = 1\n",
    "    while i < row.shape[0]:\n",
    "        if labels_np[row[i]] == base_label:\n",
    "            return i-1\n",
    "        i+=1\n",
    "    return -1\n",
    "\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "n_nearestneighbors = dist_matrix.shape[0]\n",
    "desc_dist = torch.topk(dist_matrix, dim=1, k = n_nearestneighbors, largest = False)[1]\n",
    "entire = torch.tensor([process_row(row) for row in desc_dist])\n",
    "\n",
    "n_nearestneighbors = 2\n",
    "inc_dist = torch.topk(dist_matrix, dim=1, k = n_nearestneighbors, largest = False)[1]\n",
    "just_one = torch.tensor([process_row(row) for row in inc_dist])\n",
    "\n",
    "nearest_id = desc_dist[:,1].apply_(lambda x: labels_np[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1749061f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15272)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((entire == 0).long() == just_one + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b817e1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e610c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entire[entire > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_one[just_one == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(desc_dist.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: labels_np[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    base_label = labels_np[row[0]]\n",
    "    i = 1\n",
    "    while i < row.shape[0]:\n",
    "        if labels_np[row[i]] == base_label:\n",
    "            return i-1\n",
    "        i+=1\n",
    "    return i-1\n",
    "df.apply(lambda row : process_row(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dist.apply_(lambda x: labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa018d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "torch.topk(dist_matrix, dim=1, k = 2, largest = False)[1]\n",
    "print(time.time() - t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
