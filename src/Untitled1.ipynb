{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37fad7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from head.metrics import CosFace\n",
    "from loss.focal import FocalLoss\n",
    "from utils.utils import separate_resnet_bn_paras, warm_up_lr, load_checkpoint, \\\n",
    "    schedule_lr, AverageMeter, accuracy\n",
    "from utils.fairness_utils import evaluate\n",
    "from utils.data_utils_balanced import prepare_data\n",
    "from utils.utils_train import Network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import timm\n",
    "from utils.utils import save_output_from_dict\n",
    "from utils.utils_train import Network, get_head\n",
    "from utils.fairness_utils import evaluate, add_column_to_file\n",
    "from timm.optim import create_optimizer_v2, optimizer_kwargs\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.utils.model_ema import ModelEmaV2\n",
    "from utils.fairness_utils import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device_ids=range(torch.cuda.device_count())\n",
    "torch.manual_seed(222)\n",
    "torch.cuda.manual_seed_all(222)\n",
    "np.random.seed(222)\n",
    "random.seed(222)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "default_test_root = '/cmlscratch/sdooley1/data/CelebA/Img/img_align_celeba_splits/val/'\n",
    "default_train_root = '/cmlscratch/sdooley1/data/CelebA/Img/img_align_celeba_splits/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97058fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P identities: {'male': 1.0, 'female': 1.0}\n",
      "P images: {'male': 1.0, 'female': 1.0}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--default_test_root', default=default_test_root)\n",
    "parser.add_argument('--default_train_root', default=default_train_root)\n",
    "parser.add_argument('--demographics_file', default= '/cmlscratch/sdooley1/data/CelebA/CelebA_demographics.txt')\n",
    "parser.add_argument('--backbone_name', default='mobilenetv3_large_100')\n",
    "parser.add_argument('--backbone', default='mobilenetv3_large_100')\n",
    "parser.add_argument('--pretrained', default=False)\n",
    "parser.add_argument('--project_name', default=\"from-scratch_no-resampling_adam\")\n",
    "parser.add_argument('--head', default=\"CosFace\")\n",
    "parser.add_argument('--opt', default=\"AdamW\")\n",
    "parser.add_argument('--epochs', default=100)\n",
    "parser.add_argument('--sched', default='cosine')\n",
    "parser.add_argument('--min_lr', default=0.01)\n",
    "\n",
    "parser.add_argument('--checkpoints_root', default='/cmlscratch/sdooley1/merge_timm/FR-NAS/Checkpoints/Phase1B/')\n",
    "parser.add_argument('--head_name', default='CosFace')\n",
    "parser.add_argument('--train_loss', default='Focal', type=str)\n",
    "\n",
    "parser.add_argument('--groups_to_modify', default= ['male', 'female'], type=str, nargs='+')\n",
    "parser.add_argument('--p_identities', default=[1.0, 1.0], type=float, nargs='+')\n",
    "parser.add_argument('--p_images', default=[1.0, 1.0], type=float, nargs='+')\n",
    "parser.add_argument('--min_num_images', default=3, type=int)\n",
    "\n",
    "parser.add_argument('--batch_size', default=250, type=int)\n",
    "parser.add_argument('--input_size', default=112, type=int)\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float)\n",
    "parser.add_argument('--momentum', default=0.9, type=float)\n",
    "parser.add_argument('--mean', default=[0.5, 0.5, 0.5], type=int)\n",
    "parser.add_argument('--std', default=[0.5, 0.5, 0.5], type=int)\n",
    "parser.add_argument('--stages', default=[35, 65, 95], type=int)\n",
    "parser.add_argument('--num_workers', default=4, type=int)\n",
    "\n",
    "parser.add_argument('--lr', default=0.001, type=float)\n",
    "parser.add_argument('--num_epoch', default=3, type=int)\n",
    "parser.add_argument('--gpu_id', default=[0], type=int, nargs='+', help='gpu id')\n",
    "parser.add_argument('--name', default='CelebA', type=str)\n",
    "parser.add_argument('--dataset', default='CelebA', type=str)\n",
    "parser.add_argument('--file_name', default='timm_from-scratch.csv', type=str)\n",
    "parser.add_argument('--seed', default=222, type=int)\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "p_images = {args.groups_to_modify[i]:args.p_images[i] for i in range(len(args.groups_to_modify))}\n",
    "p_identities = {args.groups_to_modify[i]:args.p_identities[i] for i in range(len(args.groups_to_modify))}\n",
    "args.p_images = p_images\n",
    "args.p_identities = p_identities\n",
    "\n",
    "print(\"P identities: {}\".format(args.p_identities))\n",
    "print(\"P images: {}\".format(args.p_images))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd74892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING TRAIN DATASET\n",
      "Overall # of images for male available is 67562\n",
      "# images selected for male is 67562\n",
      "Overall # of images for female available is 76524\n",
      "# images selected for female is 67562\n",
      "Number of idx for male is 3529\n",
      "Number of idx for female is 3529\n",
      "PREPARING TEST DATASET\n",
      "Overall # of images for male available is 8368\n",
      "# images selected for male is 7636\n",
      "Overall # of images for female available is 9618\n",
      "# images selected for female is 7636\n",
      "Number of idx for male is 438\n",
      "Number of idx for female is 438\n",
      "Len of train dataloader is 540\n",
      "Len of test dataloader is 62\n"
     ]
    }
   ],
   "source": [
    "dataloaders, num_class, demographic_to_labels_train, demographic_to_labels_test = prepare_data(args)\n",
    "args.num_class = num_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8a9e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [06:18<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "dataloader = dataloaders['train']\n",
    "df = pd.DataFrame(columns = ['ids','label','gender_expression'])\n",
    "for inputs, labels, sens_attr, indices in tqdm(iter(dataloader)):\n",
    "    df = df.append(pd.DataFrame(np.array([indices.numpy(), labels.numpy(), np.array(sens_attr)]).T,\n",
    "            columns = ['ids','label','gender_expression']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b78362bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('../Checkpoints/val_identities_gender-expression_seed_222.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6970a38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_\n",
      "Found checkpoints for this model: ['Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_80.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_20.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_101.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_60.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_40.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_100.pth']\n",
      "Loading Checkpoint '/cmlscratch/sdooley1/merge_timm/FR-NAS/Checkpoints/Phase1B/mobilenetv3_large_100_CosFace_AdamW/Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_101.pth'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' Model '''\n",
    "backbone = timm.create_model(args.backbone_name, \n",
    "                             num_classes=0,\n",
    "                             pretrained=args.pretrained).to(device)\n",
    "config = timm.data.resolve_data_config({}, model=backbone)\n",
    "model_input_size = config['input_size']\n",
    "\n",
    "# get model's embedding size\n",
    "meta = pd.read_csv('/cmlscratch/sdooley1/timm_model_metadata.csv')\n",
    "embedding_size = int(\n",
    "    meta[meta.model_name == args.backbone].feature_dim)\n",
    "args.embedding_size= embedding_size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "head = get_head(args)\n",
    "train_criterion = FocalLoss(elementwise=True)\n",
    "head,backbone= head.to(device), backbone.to(device)\n",
    "backbone = nn.DataParallel(backbone)\n",
    "####################################################################################################################\n",
    "# ======= argsimizer =======#\n",
    "model = Network(backbone, head)\n",
    "\n",
    "optimizer = create_optimizer_v2(model, **optimizer_kwargs(cfg=args))\n",
    "\n",
    "model_ema = None\n",
    "model, model_ema, optimizer, epoch, batch, checkpoints_model_root = load_checkpoint(\n",
    "    args, model, model_ema, optimizer, dataloaders[\"train\"], p_identities,\n",
    "    p_images)\n",
    "#model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562d6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:11<00:00,  5.21it/s]\n"
     ]
    }
   ],
   "source": [
    "demographic_to_labels = demographic_to_labels_train\n",
    "loss = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "acc = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "count = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "acc_k = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "intra = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "inter = {k:torch.tensor(0.0) for k in demographic_to_labels.keys()}\n",
    "angles_intra, angles_inter, correct = 0, 0, 0\n",
    "\n",
    "#backbone.eval()\n",
    "#if multilabel_accuracy:\n",
    "#    head.eval()\n",
    "model.eval()\n",
    "# figure out embedding size\n",
    "emb_size = embedding_size\n",
    "dataloader = dataloaders['test']\n",
    "if emb_size is None:\n",
    "    inputs, _, _ = next(iter(dataloader))\n",
    "    x = torch.randn(inputs.shape).to(device)\n",
    "    emb_size = backbone(x).shape[1]\n",
    "\n",
    "\n",
    "feature_matrix = torch.empty(0, emb_size)\n",
    "labels_all = []\n",
    "indices_all = []\n",
    "demographic_all = []\n",
    "predicted_all = []\n",
    "\n",
    "for inputs, labels, sens_attr, indices in tqdm(iter(dataloader)):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).long()\n",
    "    labels_all = labels_all + labels.cpu().tolist()\n",
    "    indices_all = indices_all + indices.cpu().tolist()\n",
    "    sens_attr = np.array(sens_attr)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if True:\n",
    "            #need to build feature matrix\n",
    "            inputs_flipped = torch.flip(inputs, [3])\n",
    "            try:\n",
    "                embed = model.module.backbone(inputs) + model.module.backbone(inputs_flipped)\n",
    "            except AttributeError:\n",
    "                embed = model.backbone(inputs) + model.backbone(inputs_flipped)\n",
    "            features_batch = l2_norm(embed)\n",
    "            feature_matrix = torch.cat((feature_matrix, features_batch.detach().cpu()), dim = 0)\n",
    "\n",
    "            demographic_all = demographic_all + sens_attr.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9160439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, labels, demographic_to_labels, test_features, test_labels, test_demographic = feature_matrix, torch.tensor(labels_all), demographic_to_labels, feature_matrix, torch.tensor(labels_all), np.array(demographic_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1489a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix =  l2_dist(feature_matrix, feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f8a094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2038564682006836\n"
     ]
    }
   ],
   "source": [
    "acc_k = {k:0 for k in demographic_to_labels.keys()}\n",
    "nearest_neighbors = torch.topk(dist_matrix, dim=1, k = 2, largest = False)[1][:,1]\n",
    "n_images = dist_matrix.shape[0]\n",
    "correct = torch.zeros(test_labels.shape)\n",
    "nearest_id = torch.zeros(test_labels.shape)\n",
    "\n",
    "t = time.time()\n",
    "for img in range(n_images):\n",
    "    nearest_label = labels[nearest_neighbors[img]].item()\n",
    "    nearest_id[img] = nearest_label\n",
    "    label_img = test_labels[img].item()\n",
    "    if label_img == nearest_label:\n",
    "        correct[img] = 1\n",
    "print(time.time()-t)\n",
    "for k in acc_k.keys():\n",
    "    acc_k[k] = (correct[test_demographic == k]).mean()\n",
    "\n",
    "# acc_k, \n",
    "# correct = torch.tensor(just_one + 1)\n",
    "# nearest_id = torch.tensor(df[1].apply(lambda x: labels_np[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "936ee3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = True\n",
    "def process_row(row, labels_np):\n",
    "    \"\"\" \n",
    "    given a row where the row is a list of image ids where this list increases\n",
    "    in distance in the featue space where the first point is the refernce point.\n",
    "    returns the index of the closest point with the same label, if no such point, returns -1\n",
    "    \"\"\"\n",
    "    base_label = labels_np[row[0]]\n",
    "    n_img = 1\n",
    "    n_id = 1\n",
    "    ids = set()\n",
    "    while n_img < row.shape[0]:\n",
    "        # add this id to the set of \n",
    "        ids.add(labels_np[row[n_img]])\n",
    "        if labels_np[row[n_img]] == base_label:\n",
    "            return n_img-1, len(list(ids))-1\n",
    "        n_img+=1\n",
    "    return -1,-1\n",
    "\n",
    "# if rank is true, then compute the rank of the prediction\n",
    "if rank == True:\n",
    "    k = test_features.shape[0]\n",
    "# otherwise, just compute the accuracy\n",
    "else:\n",
    "    k = 2\n",
    "\n",
    "dist_matrix =  l2_dist(feature_matrix, test_features)\n",
    "labels_np = labels.numpy()\n",
    "inc_dist = torch.topk(dist_matrix, dim=1, k = k, largest = False)[1]\n",
    "nearest_same_label = torch.tensor([process_row(row, labels_np) for row in inc_dist])\n",
    "\n",
    "correct = (nearest_same_label[:,0] == 0).long()\n",
    "nearest_id = inc_dist[:,1].apply_(lambda x: labels_np[x])\n",
    "acc_k = {}\n",
    "for k in acc_k.keys():\n",
    "    acc_k[k] = (correct[test_demographic == k]).mean()\n",
    "\n",
    "return acc_k, correct, nearest_id, nearest_same_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37d4341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  7,   7],\n",
       "        [279, 107],\n",
       "        [  1,   1],\n",
       "        ...,\n",
       "        [  2,   2],\n",
       "        [  7,   7],\n",
       "        [303, 162]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_same_label[nearest_same_label[:,0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1749061f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15272)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((entire == 0).long() == just_one + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b817e1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e610c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entire[entire > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_one[just_one == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(desc_dist.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: labels_np[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    base_label = labels_np[row[0]]\n",
    "    i = 1\n",
    "    while i < row.shape[0]:\n",
    "        if labels_np[row[i]] == base_label:\n",
    "            return i-1\n",
    "        i+=1\n",
    "    return i-1\n",
    "df.apply(lambda row : process_row(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dist.apply_(lambda x: labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fa018d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_20.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_40.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_60.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_80.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_100.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_101.pth']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = ['Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_80.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_20.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_101.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_60.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_40.pth', 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_100.pth']\n",
    "\n",
    "foo.sort(key = lambda x: int(x.split('Epoch_')[1].split('.')[0]))\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0234c05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_20.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_40.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_60.pth',\n",
       " 'Checkpoint_Head_CosFace_Backbone_mobilenetv3_large_100_Opt_AdamW_Dataset_CelebA_Epoch_80.pth']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: int(x.split('Epoch_')[1].split('.')[0]) in [20,40,60,80,100], ckpts ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb08dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:12<00:00,  4.82it/s]\n"
     ]
    }
   ],
   "source": [
    "k_accuracy = True\n",
    "multilabel_accuracy = True\n",
    "comp_rank = True\n",
    "loss, acc, acc_k, predicted_all, intra, inter, angles_intra, angles_inter, correct, nearest_id, labels_all, indices_all, demographic_all, rank = evaluate(\n",
    "    dataloaders[\"test\"],\n",
    "    train_criterion,\n",
    "    model,\n",
    "    embedding_size,\n",
    "    k_accuracy=k_accuracy,\n",
    "    multilabel_accuracy=multilabel_accuracy,\n",
    "    demographic_to_labels=demographic_to_labels_test,\n",
    "    test=True, rank=comp_rank)\n",
    "\n",
    "rank_by_id = pd.DataFrame(np.array([list(indices_all),\n",
    "                                    list(rank[:,1])]).T,\n",
    "                          columns=['ids','rank_by_id']).astype(int)\n",
    "\n",
    "metadata = pd.read_csv('../Checkpoints/val_identities_gender-expression_seed_222.csv')\n",
    "df = rank_by_id.merge(metadata)\n",
    "\n",
    "def rank_ratio_func(df):\n",
    "    # calculate the ratio of ranks\n",
    "    data = {}\n",
    "    for g,g_df in df.groupby('gender_expression'):\n",
    "        data[g] = (g_df['rank_by_id']).sum(axis=0)/g_df.shape[0]\n",
    "    return data['male']/data['female']\n",
    "\n",
    "rank_ratio_func(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015d6808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59,\n",
       " 59,\n",
       " 59,\n",
       " 99,\n",
       " 99,\n",
       " 99,\n",
       " 162,\n",
       " 162,\n",
       " 162,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 300,\n",
       " 300,\n",
       " 300,\n",
       " 272,\n",
       " 272,\n",
       " 272,\n",
       " 324,\n",
       " 324,\n",
       " 324,\n",
       " 430,\n",
       " 430,\n",
       " 430,\n",
       " 306,\n",
       " 306,\n",
       " 306,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 238,\n",
       " 238,\n",
       " 238,\n",
       " 78,\n",
       " 78,\n",
       " 78,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 313,\n",
       " 313,\n",
       " 313,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 218,\n",
       " 218,\n",
       " 218,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 415,\n",
       " 415,\n",
       " 415,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 179,\n",
       " 179,\n",
       " 179,\n",
       " 377,\n",
       " 377,\n",
       " 377,\n",
       " 277,\n",
       " 277,\n",
       " 277,\n",
       " 359,\n",
       " 359,\n",
       " 359,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 285,\n",
       " 285,\n",
       " 285,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 370,\n",
       " 370,\n",
       " 370,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 212,\n",
       " 212,\n",
       " 212,\n",
       " 139,\n",
       " 139,\n",
       " 139,\n",
       " 295,\n",
       " 295,\n",
       " 295,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 284,\n",
       " 284,\n",
       " 284,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 251,\n",
       " 251,\n",
       " 251,\n",
       " 157,\n",
       " 157,\n",
       " 157,\n",
       " 223,\n",
       " 223,\n",
       " 223,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 289,\n",
       " 289,\n",
       " 289,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 53,\n",
       " 53,\n",
       " 53,\n",
       " 371,\n",
       " 371,\n",
       " 371,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 227,\n",
       " 227,\n",
       " 227,\n",
       " 279,\n",
       " 279,\n",
       " 279,\n",
       " 381,\n",
       " 381,\n",
       " 381,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 192,\n",
       " 192,\n",
       " 192,\n",
       " 374,\n",
       " 374,\n",
       " 374,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 229,\n",
       " 229,\n",
       " 229,\n",
       " 101,\n",
       " 101,\n",
       " 101,\n",
       " 315,\n",
       " 315,\n",
       " 315,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 234,\n",
       " 234,\n",
       " 234,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 174,\n",
       " 174,\n",
       " 174,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 258,\n",
       " 258,\n",
       " 258,\n",
       " 268,\n",
       " 268,\n",
       " 268,\n",
       " 317,\n",
       " 317,\n",
       " 317,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 79,\n",
       " 79,\n",
       " 79,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 334,\n",
       " 334,\n",
       " 334,\n",
       " 220,\n",
       " 220,\n",
       " 220,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 345,\n",
       " 345,\n",
       " 345,\n",
       " 176,\n",
       " 176,\n",
       " 176,\n",
       " 98,\n",
       " 98,\n",
       " 98,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 302,\n",
       " 302,\n",
       " 302,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 437,\n",
       " 437,\n",
       " 437,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 198,\n",
       " 198,\n",
       " 198,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 181,\n",
       " 181,\n",
       " 181,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 96,\n",
       " 96,\n",
       " 96,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 95,\n",
       " 95,\n",
       " 95,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 187,\n",
       " 187,\n",
       " 187,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 325,\n",
       " 325,\n",
       " 325,\n",
       " 228,\n",
       " 228,\n",
       " 228,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 219,\n",
       " 219,\n",
       " 219,\n",
       " 362,\n",
       " 362,\n",
       " 362,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 401,\n",
       " 401,\n",
       " 401,\n",
       " 242,\n",
       " 242,\n",
       " 242,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 102,\n",
       " 102,\n",
       " 102,\n",
       " 57,\n",
       " 57,\n",
       " 57,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 423,\n",
       " 423,\n",
       " 423,\n",
       " 213,\n",
       " 213,\n",
       " 213,\n",
       " 420,\n",
       " 420,\n",
       " 420,\n",
       " 322,\n",
       " 322,\n",
       " 322,\n",
       " 142,\n",
       " 142,\n",
       " 142,\n",
       " 394,\n",
       " 394,\n",
       " 394,\n",
       " 321,\n",
       " 321,\n",
       " 321,\n",
       " 156,\n",
       " 156,\n",
       " 156,\n",
       " 245,\n",
       " 245,\n",
       " 245,\n",
       " 436,\n",
       " 436,\n",
       " 436,\n",
       " 336,\n",
       " 336,\n",
       " 336,\n",
       " 106,\n",
       " 106,\n",
       " 106,\n",
       " 203,\n",
       " 203,\n",
       " 203,\n",
       " 319,\n",
       " 319,\n",
       " 319,\n",
       " 154,\n",
       " 154,\n",
       " 154,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 256,\n",
       " 256,\n",
       " 256,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 262,\n",
       " 262,\n",
       " 262,\n",
       " 248,\n",
       " 248,\n",
       " 248,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 145,\n",
       " 145,\n",
       " 145,\n",
       " 247,\n",
       " 247,\n",
       " 247,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 226,\n",
       " 226,\n",
       " 226,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 344,\n",
       " 344,\n",
       " 344,\n",
       " 387,\n",
       " 387,\n",
       " 387,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 326,\n",
       " 326,\n",
       " 326,\n",
       " 307,\n",
       " 307,\n",
       " 307,\n",
       " 383,\n",
       " 383,\n",
       " 383,\n",
       " 327,\n",
       " 327,\n",
       " 327,\n",
       " 202,\n",
       " 202,\n",
       " 202,\n",
       " 81,\n",
       " 81,\n",
       " 81,\n",
       " 252,\n",
       " 252,\n",
       " 252,\n",
       " 391,\n",
       " 391,\n",
       " 391,\n",
       " 406,\n",
       " 406,\n",
       " 406,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 366,\n",
       " 366,\n",
       " 366,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 222,\n",
       " 222,\n",
       " 222,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 269,\n",
       " 269,\n",
       " 269,\n",
       " 287,\n",
       " 287,\n",
       " 287,\n",
       " 405,\n",
       " 405,\n",
       " 405,\n",
       " 435,\n",
       " 435,\n",
       " 435,\n",
       " 168,\n",
       " 168,\n",
       " 168,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 411,\n",
       " 411,\n",
       " 411,\n",
       " 164,\n",
       " 164,\n",
       " 164,\n",
       " 363,\n",
       " 363,\n",
       " 363,\n",
       " 257,\n",
       " 257,\n",
       " 257,\n",
       " 403,\n",
       " 403,\n",
       " 403,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 119,\n",
       " 119,\n",
       " 119,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 354,\n",
       " 354,\n",
       " 354,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 393,\n",
       " 393,\n",
       " 393,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 433,\n",
       " 433,\n",
       " 433,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 392,\n",
       " 392,\n",
       " 392,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 107,\n",
       " 107,\n",
       " 107,\n",
       " 299,\n",
       " 299,\n",
       " 299,\n",
       " 183,\n",
       " 183,\n",
       " 183,\n",
       " 244,\n",
       " 244,\n",
       " 244,\n",
       " 337,\n",
       " 337,\n",
       " 337,\n",
       " 209,\n",
       " 209,\n",
       " 209,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 304,\n",
       " 304,\n",
       " 304,\n",
       " 253,\n",
       " 253,\n",
       " 253,\n",
       " 402,\n",
       " 402,\n",
       " 402,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 419,\n",
       " 419,\n",
       " 419,\n",
       " 407,\n",
       " 407,\n",
       " 407,\n",
       " 428,\n",
       " 428,\n",
       " 428,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 297,\n",
       " 297,\n",
       " 297,\n",
       " 331,\n",
       " 331,\n",
       " 331,\n",
       " 424,\n",
       " 424,\n",
       " 424,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 201,\n",
       " 201,\n",
       " 201,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 259,\n",
       " 259,\n",
       " 259,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 343,\n",
       " 343,\n",
       " 343,\n",
       " 417,\n",
       " 417,\n",
       " 417,\n",
       " 369,\n",
       " 369,\n",
       " 369,\n",
       " 274,\n",
       " 274,\n",
       " 274,\n",
       " 395,\n",
       " 395,\n",
       " 395,\n",
       " 75,\n",
       " 75,\n",
       " 75,\n",
       " 335,\n",
       " 335,\n",
       " 335,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 384,\n",
       " 384,\n",
       " 384,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 122,\n",
       " 122,\n",
       " 122,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 373,\n",
       " 373,\n",
       " 373,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 333,\n",
       " 333,\n",
       " 333,\n",
       " 281,\n",
       " 281,\n",
       " 281,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 77,\n",
       " 77,\n",
       " 77,\n",
       " 288,\n",
       " 288,\n",
       " 288,\n",
       " 186,\n",
       " 186,\n",
       " 186,\n",
       " 205,\n",
       " 205,\n",
       " 205,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 303,\n",
       " 303,\n",
       " 303,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 196,\n",
       " 196,\n",
       " 196,\n",
       " 231,\n",
       " 231,\n",
       " 231,\n",
       " 372,\n",
       " 372,\n",
       " 372,\n",
       " 185,\n",
       " 185,\n",
       " 185,\n",
       " 389,\n",
       " 389,\n",
       " 389,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 397,\n",
       " 397,\n",
       " 397,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 301,\n",
       " 301,\n",
       " 301,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 314,\n",
       " 314,\n",
       " 314,\n",
       " 278,\n",
       " 278,\n",
       " 278,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 412,\n",
       " 412,\n",
       " 412,\n",
       " 292,\n",
       " 292,\n",
       " 292,\n",
       " 332,\n",
       " 332,\n",
       " 332,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 103,\n",
       " 103,\n",
       " 103,\n",
       " 426,\n",
       " 426,\n",
       " 426,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 310,\n",
       " 310,\n",
       " 310,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 427,\n",
       " 427,\n",
       " 427,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 376,\n",
       " 376,\n",
       " 376,\n",
       " 388,\n",
       " 388,\n",
       " 388,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 215,\n",
       " 215,\n",
       " 215,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 146,\n",
       " 146,\n",
       " 146,\n",
       " 316,\n",
       " 316,\n",
       " 316,\n",
       " 266,\n",
       " 266,\n",
       " 266,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 367,\n",
       " 367,\n",
       " 367,\n",
       " 422,\n",
       " 422,\n",
       " 422,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 286,\n",
       " 286,\n",
       " 286,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 195,\n",
       " 195,\n",
       " 195,\n",
       " 400,\n",
       " 400,\n",
       " 400,\n",
       " 184,\n",
       " 184,\n",
       " 184,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 151,\n",
       " 151,\n",
       " 151,\n",
       " 312,\n",
       " 312,\n",
       " 312,\n",
       " 171,\n",
       " 171,\n",
       " 171,\n",
       " 175,\n",
       " 175,\n",
       " 175,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 267,\n",
       " 267,\n",
       " 267,\n",
       " 82,\n",
       " 82,\n",
       " 82,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 134,\n",
       " 134,\n",
       " 134,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 73,\n",
       " 73,\n",
       " 73,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 283,\n",
       " 283,\n",
       " 283,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 275,\n",
       " 275,\n",
       " 275,\n",
       " 421,\n",
       " 421,\n",
       " 421,\n",
       " 431,\n",
       " 431,\n",
       " 431,\n",
       " 360,\n",
       " 360,\n",
       " 360,\n",
       " 147,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "196f1861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8374023273751635"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_ratio_func(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
